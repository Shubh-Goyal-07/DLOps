{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y9afYFkNmqLL"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWBJ2SGfm7b3",
        "outputId": "ba90b4d6-11f0-435f-cbe0-6bc80021ef61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ray in /usr/local/lib/python3.11/dist-packages (2.43.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray) (3.17.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray) (24.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray) (4.25.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ray) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray) (1.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray) (2.32.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (0.23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->ray) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ray #[tune]==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "13QB7aO4mqLN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tempfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from filelock import FileLock\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from typing import Dict\n",
        "import ray\n",
        "from ray import train, tune, get, put\n",
        "from ray.train import Checkpoint\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jB0DIK_HmqLO"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_filters=32, dropout_rate=0.5):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, num_filters, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_filters)\n",
        "        self.conv2 = nn.Conv2d(num_filters, num_filters * 2, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(num_filters * 2)\n",
        "        self.fc1 = nn.Linear(num_filters * 2 * 8 * 8, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(self.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-Pje07-WfwEX"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "trainset_ref = put(trainset)\n",
        "testset_ref = put(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6dQmqN8fgDL_"
      },
      "outputs": [],
      "source": [
        "def train_cifar(config, checkpoint_dir=None):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    trainset = get(trainset_ref)\n",
        "    testset = get(testset_ref)\n",
        "\n",
        "    trainloader = DataLoader(trainset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=2)\n",
        "    testloader = DataLoader(testset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=2)\n",
        "\n",
        "    model = CNN(num_filters=config[\"num_filters\"], dropout_rate=config[\"dropout\"]).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    for epoch in range(10):\n",
        "        print(f\"Epoch {epoch + 1}\")\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        accuracy = correct / total\n",
        "        tune.report(metrics = {\"loss\": running_loss / len(trainloader), \"accuracy\": accuracy*100})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GGawMobNgR9Q"
      },
      "outputs": [],
      "source": [
        "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=0):\n",
        "    config = {\n",
        "        \"num_filters\": tune.choice([16, 32, 64, 128]),\n",
        "        \"lr\": tune.choice([1e-2, 1e-3]),\n",
        "        \"batch_size\": tune.choice([16, 32, 64]),\n",
        "        \"dropout\": tune.choice([0.3, 0.4, 0.5])\n",
        "    }\n",
        "    scheduler = ASHAScheduler(max_t=max_num_epochs, grace_period=1, reduction_factor=2)\n",
        "    tuner = tune.Tuner(\n",
        "        tune.with_resources(tune.with_parameters(train_cifar), resources={\"cpu\": 2, \"gpu\": gpus_per_trial}),\n",
        "        tune_config=tune.TuneConfig(metric=\"loss\", mode=\"min\", scheduler=scheduler, num_samples=num_samples),\n",
        "        param_space=config,\n",
        "    )\n",
        "    results = tuner.fit()\n",
        "    best_result = results.get_best_result(\"loss\", \"min\")\n",
        "    print(\"Best Config:\", best_result.config)\n",
        "    print(\"Best Validation Accuracy:\", best_result.metrics[\"accuracy\"])\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = main(num_samples=20, max_num_epochs=10, gpus_per_trial=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s--rdoKAVels",
        "outputId": "40de7ff7-e018-4814-aee3-9d44e3a512ca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-17 18:49:16,292\tWARNING callback.py:136 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     train_cifar_2025-03-17_18-49-16   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator             |\n",
            "| Scheduler                        AsyncHyperBandScheduler           |\n",
            "| Number of trials                 20                                |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/train_cifar_2025-03-17_18-49-16\n",
            "\n",
            "Trial status: 20 PENDING\n",
            "Current time: 2025-03-17 18:49:16. Total running time: 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Trial name                status       num_filters      lr     batch_size     dropout |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00000   PENDING               64   0.01              32         0.4 |\n",
            "| train_cifar_86ddf_00001   PENDING               16   0.001             16         0.3 |\n",
            "| train_cifar_86ddf_00002   PENDING               64   0.01              16         0.4 |\n",
            "| train_cifar_86ddf_00003   PENDING               16   0.01              16         0.4 |\n",
            "| train_cifar_86ddf_00004   PENDING               16   0.01              16         0.3 |\n",
            "| train_cifar_86ddf_00005   PENDING              128   0.01              64         0.4 |\n",
            "| train_cifar_86ddf_00006   PENDING               32   0.01              32         0.3 |\n",
            "| train_cifar_86ddf_00007   PENDING               32   0.01              32         0.4 |\n",
            "| train_cifar_86ddf_00008   PENDING              128   0.001             32         0.5 |\n",
            "| train_cifar_86ddf_00009   PENDING              128   0.01              16         0.4 |\n",
            "| train_cifar_86ddf_00010   PENDING              128   0.01              32         0.4 |\n",
            "| train_cifar_86ddf_00011   PENDING               64   0.01              16         0.5 |\n",
            "| train_cifar_86ddf_00012   PENDING               32   0.001             64         0.3 |\n",
            "| train_cifar_86ddf_00013   PENDING              128   0.001             16         0.5 |\n",
            "| train_cifar_86ddf_00014   PENDING              128   0.001             32         0.3 |\n",
            "| train_cifar_86ddf_00015   PENDING               16   0.001             64         0.5 |\n",
            "| train_cifar_86ddf_00016   PENDING              128   0.001             32         0.3 |\n",
            "| train_cifar_86ddf_00017   PENDING               16   0.01              64         0.3 |\n",
            "| train_cifar_86ddf_00018   PENDING               16   0.001             64         0.3 |\n",
            "| train_cifar_86ddf_00019   PENDING               64   0.01              32         0.5 |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00000 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00000 config          |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                                 32 |\n",
            "| dropout                                   0.4 |\n",
            "| lr                                       0.01 |\n",
            "| num_filters                                64 |\n",
            "+-----------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=13702)\u001b[0m Epoch 1\n",
            "\u001b[36m(train_cifar pid=13702)\u001b[0m Epoch 2\n",
            "\n",
            "Trial status: 1 RUNNING | 19 PENDING\n",
            "Current time: 2025-03-17 18:49:46. Total running time: 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00000 with loss=2.4917751536183226 and params={'num_filters': 64, 'lr': 0.01, 'batch_size': 32, 'dropout': 0.4}\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status       num_filters      lr     batch_size     dropout     iter     total time (s)      loss     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00000   RUNNING               64   0.01              32         0.4        1            20.8025   2.49178           10 |\n",
            "| train_cifar_86ddf_00001   PENDING               16   0.001             16         0.3                                                    |\n",
            "| train_cifar_86ddf_00002   PENDING               64   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00003   PENDING               16   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00004   PENDING               16   0.01              16         0.3                                                    |\n",
            "| train_cifar_86ddf_00005   PENDING              128   0.01              64         0.4                                                    |\n",
            "| train_cifar_86ddf_00006   PENDING               32   0.01              32         0.3                                                    |\n",
            "| train_cifar_86ddf_00007   PENDING               32   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00008   PENDING              128   0.001             32         0.5                                                    |\n",
            "| train_cifar_86ddf_00009   PENDING              128   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00010   PENDING              128   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00011   PENDING               64   0.01              16         0.5                                                    |\n",
            "| train_cifar_86ddf_00012   PENDING               32   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00013   PENDING              128   0.001             16         0.5                                                    |\n",
            "| train_cifar_86ddf_00014   PENDING              128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00015   PENDING               16   0.001             64         0.5                                                    |\n",
            "| train_cifar_86ddf_00016   PENDING              128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00017   PENDING               16   0.01              64         0.3                                                    |\n",
            "| train_cifar_86ddf_00018   PENDING               16   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00019   PENDING               64   0.01              32         0.5                                                    |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=13702)\u001b[0m Epoch 3\n",
            "Trial status: 1 RUNNING | 19 PENDING\n",
            "Current time: 2025-03-17 18:50:16. Total running time: 1min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00000 with loss=2.3039729110110057 and params={'num_filters': 64, 'lr': 0.01, 'batch_size': 32, 'dropout': 0.4}\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status       num_filters      lr     batch_size     dropout     iter     total time (s)      loss     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00000   RUNNING               64   0.01              32         0.4        2            40.2797   2.30397           10 |\n",
            "| train_cifar_86ddf_00001   PENDING               16   0.001             16         0.3                                                    |\n",
            "| train_cifar_86ddf_00002   PENDING               64   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00003   PENDING               16   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00004   PENDING               16   0.01              16         0.3                                                    |\n",
            "| train_cifar_86ddf_00005   PENDING              128   0.01              64         0.4                                                    |\n",
            "| train_cifar_86ddf_00006   PENDING               32   0.01              32         0.3                                                    |\n",
            "| train_cifar_86ddf_00007   PENDING               32   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00008   PENDING              128   0.001             32         0.5                                                    |\n",
            "| train_cifar_86ddf_00009   PENDING              128   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00010   PENDING              128   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00011   PENDING               64   0.01              16         0.5                                                    |\n",
            "| train_cifar_86ddf_00012   PENDING               32   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00013   PENDING              128   0.001             16         0.5                                                    |\n",
            "| train_cifar_86ddf_00014   PENDING              128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00015   PENDING               16   0.001             64         0.5                                                    |\n",
            "| train_cifar_86ddf_00016   PENDING              128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00017   PENDING               16   0.01              64         0.3                                                    |\n",
            "| train_cifar_86ddf_00018   PENDING               16   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00019   PENDING               64   0.01              32         0.5                                                    |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=13702)\u001b[0m Epoch 4\n",
            "\u001b[36m(train_cifar pid=13702)\u001b[0m Epoch 5\n",
            "Trial status: 1 RUNNING | 19 PENDING\n",
            "Current time: 2025-03-17 18:50:46. Total running time: 1min 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00000 with loss=2.303964753221108 and params={'num_filters': 64, 'lr': 0.01, 'batch_size': 32, 'dropout': 0.4}\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status       num_filters      lr     batch_size     dropout     iter     total time (s)      loss     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00000   RUNNING               64   0.01              32         0.4        4            77.5012   2.30396           10 |\n",
            "| train_cifar_86ddf_00001   PENDING               16   0.001             16         0.3                                                    |\n",
            "| train_cifar_86ddf_00002   PENDING               64   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00003   PENDING               16   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00004   PENDING               16   0.01              16         0.3                                                    |\n",
            "| train_cifar_86ddf_00005   PENDING              128   0.01              64         0.4                                                    |\n",
            "| train_cifar_86ddf_00006   PENDING               32   0.01              32         0.3                                                    |\n",
            "| train_cifar_86ddf_00007   PENDING               32   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00008   PENDING              128   0.001             32         0.5                                                    |\n",
            "| train_cifar_86ddf_00009   PENDING              128   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00010   PENDING              128   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00011   PENDING               64   0.01              16         0.5                                                    |\n",
            "| train_cifar_86ddf_00012   PENDING               32   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00013   PENDING              128   0.001             16         0.5                                                    |\n",
            "| train_cifar_86ddf_00014   PENDING              128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00015   PENDING               16   0.001             64         0.5                                                    |\n",
            "| train_cifar_86ddf_00016   PENDING              128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00017   PENDING               16   0.01              64         0.3                                                    |\n",
            "| train_cifar_86ddf_00018   PENDING               16   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00019   PENDING               64   0.01              32         0.5                                                    |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=13702)\u001b[0m Epoch 6\n",
            "\u001b[36m(train_cifar pid=13702)\u001b[0m Epoch 7\n",
            "Trial status: 1 RUNNING | 19 PENDING\n",
            "Current time: 2025-03-17 18:51:16. Total running time: 2min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00000 with loss=2.3039956655703673 and params={'num_filters': 64, 'lr': 0.01, 'batch_size': 32, 'dropout': 0.4}\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status       num_filters      lr     batch_size     dropout     iter     total time (s)     loss     accuracy |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00000   RUNNING               64   0.01              32         0.4        6            114.746    2.304           10 |\n",
            "| train_cifar_86ddf_00001   PENDING               16   0.001             16         0.3                                                   |\n",
            "| train_cifar_86ddf_00002   PENDING               64   0.01              16         0.4                                                   |\n",
            "| train_cifar_86ddf_00003   PENDING               16   0.01              16         0.4                                                   |\n",
            "| train_cifar_86ddf_00004   PENDING               16   0.01              16         0.3                                                   |\n",
            "| train_cifar_86ddf_00005   PENDING              128   0.01              64         0.4                                                   |\n",
            "| train_cifar_86ddf_00006   PENDING               32   0.01              32         0.3                                                   |\n",
            "| train_cifar_86ddf_00007   PENDING               32   0.01              32         0.4                                                   |\n",
            "| train_cifar_86ddf_00008   PENDING              128   0.001             32         0.5                                                   |\n",
            "| train_cifar_86ddf_00009   PENDING              128   0.01              16         0.4                                                   |\n",
            "| train_cifar_86ddf_00010   PENDING              128   0.01              32         0.4                                                   |\n",
            "| train_cifar_86ddf_00011   PENDING               64   0.01              16         0.5                                                   |\n",
            "| train_cifar_86ddf_00012   PENDING               32   0.001             64         0.3                                                   |\n",
            "| train_cifar_86ddf_00013   PENDING              128   0.001             16         0.5                                                   |\n",
            "| train_cifar_86ddf_00014   PENDING              128   0.001             32         0.3                                                   |\n",
            "| train_cifar_86ddf_00015   PENDING               16   0.001             64         0.5                                                   |\n",
            "| train_cifar_86ddf_00016   PENDING              128   0.001             32         0.3                                                   |\n",
            "| train_cifar_86ddf_00017   PENDING               16   0.01              64         0.3                                                   |\n",
            "| train_cifar_86ddf_00018   PENDING               16   0.001             64         0.3                                                   |\n",
            "| train_cifar_86ddf_00019   PENDING               64   0.01              32         0.5                                                   |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=13702)\u001b[0m Epoch 8\n",
            "Trial status: 1 RUNNING | 19 PENDING\n",
            "Current time: 2025-03-17 18:51:46. Total running time: 2min 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00000 with loss=2.3042483087235817 and params={'num_filters': 64, 'lr': 0.01, 'batch_size': 32, 'dropout': 0.4}\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status       num_filters      lr     batch_size     dropout     iter     total time (s)      loss     accuracy |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00000   RUNNING               64   0.01              32         0.4        7             134.24   2.30425           10 |\n",
            "| train_cifar_86ddf_00001   PENDING               16   0.001             16         0.3                                                    |\n",
            "| train_cifar_86ddf_00002   PENDING               64   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00003   PENDING               16   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00004   PENDING               16   0.01              16         0.3                                                    |\n",
            "| train_cifar_86ddf_00005   PENDING              128   0.01              64         0.4                                                    |\n",
            "| train_cifar_86ddf_00006   PENDING               32   0.01              32         0.3                                                    |\n",
            "| train_cifar_86ddf_00007   PENDING               32   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00008   PENDING              128   0.001             32         0.5                                                    |\n",
            "| train_cifar_86ddf_00009   PENDING              128   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00010   PENDING              128   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00011   PENDING               64   0.01              16         0.5                                                    |\n",
            "| train_cifar_86ddf_00012   PENDING               32   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00013   PENDING              128   0.001             16         0.5                                                    |\n",
            "| train_cifar_86ddf_00014   PENDING              128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00015   PENDING               16   0.001             64         0.5                                                    |\n",
            "| train_cifar_86ddf_00016   PENDING              128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00017   PENDING               16   0.01              64         0.3                                                    |\n",
            "| train_cifar_86ddf_00018   PENDING               16   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00019   PENDING               64   0.01              32         0.5                                                    |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=13702)\u001b[0m Epoch 9\n",
            "\u001b[36m(train_cifar pid=13702)\u001b[0m Epoch 10\n",
            "Trial status: 1 RUNNING | 19 PENDING\n",
            "Current time: 2025-03-17 18:52:17. Total running time: 3min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00000 with loss=2.3038026961621303 and params={'num_filters': 64, 'lr': 0.01, 'batch_size': 32, 'dropout': 0.4}\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status       num_filters      lr     batch_size     dropout     iter     total time (s)     loss     accuracy |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00000   RUNNING               64   0.01              32         0.4        9            172.025   2.3038           10 |\n",
            "| train_cifar_86ddf_00001   PENDING               16   0.001             16         0.3                                                   |\n",
            "| train_cifar_86ddf_00002   PENDING               64   0.01              16         0.4                                                   |\n",
            "| train_cifar_86ddf_00003   PENDING               16   0.01              16         0.4                                                   |\n",
            "| train_cifar_86ddf_00004   PENDING               16   0.01              16         0.3                                                   |\n",
            "| train_cifar_86ddf_00005   PENDING              128   0.01              64         0.4                                                   |\n",
            "| train_cifar_86ddf_00006   PENDING               32   0.01              32         0.3                                                   |\n",
            "| train_cifar_86ddf_00007   PENDING               32   0.01              32         0.4                                                   |\n",
            "| train_cifar_86ddf_00008   PENDING              128   0.001             32         0.5                                                   |\n",
            "| train_cifar_86ddf_00009   PENDING              128   0.01              16         0.4                                                   |\n",
            "| train_cifar_86ddf_00010   PENDING              128   0.01              32         0.4                                                   |\n",
            "| train_cifar_86ddf_00011   PENDING               64   0.01              16         0.5                                                   |\n",
            "| train_cifar_86ddf_00012   PENDING               32   0.001             64         0.3                                                   |\n",
            "| train_cifar_86ddf_00013   PENDING              128   0.001             16         0.5                                                   |\n",
            "| train_cifar_86ddf_00014   PENDING              128   0.001             32         0.3                                                   |\n",
            "| train_cifar_86ddf_00015   PENDING               16   0.001             64         0.5                                                   |\n",
            "| train_cifar_86ddf_00016   PENDING              128   0.001             32         0.3                                                   |\n",
            "| train_cifar_86ddf_00017   PENDING               16   0.01              64         0.3                                                   |\n",
            "| train_cifar_86ddf_00018   PENDING               16   0.001             64         0.3                                                   |\n",
            "| train_cifar_86ddf_00019   PENDING               64   0.01              32         0.5                                                   |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00000 completed after 10 iterations at 2025-03-17 18:52:32. Total running time: 3min 15s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00000 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         18.8054 |\n",
            "| time_total_s                             190.831 |\n",
            "| training_iteration                            10 |\n",
            "| accuracy                                      10 |\n",
            "| loss                                     2.30382 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00001 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00001 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  16 |\n",
            "| dropout                                    0.3 |\n",
            "| lr                                       0.001 |\n",
            "| num_filters                                 16 |\n",
            "+------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=14773)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 18 PENDING\n",
            "Current time: 2025-03-17 18:52:47. Total running time: 3min 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00000 with loss=2.303820137327784 and params={'num_filters': 64, 'lr': 0.01, 'batch_size': 32, 'dropout': 0.4}\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)      loss     accuracy |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00001   RUNNING                 16   0.001             16         0.3                                                    |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10            190.831   2.30382           10 |\n",
            "| train_cifar_86ddf_00002   PENDING                 64   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00003   PENDING                 16   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00004   PENDING                 16   0.01              16         0.3                                                    |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                    |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                    |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                    |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                    |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                    |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                    |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                    |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                    |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=14773)\u001b[0m Epoch 2\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 18 PENDING\n",
            "Current time: 2025-03-17 18:53:17. Total running time: 4min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=1.3879272493934631 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)      loss     accuracy |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00001   RUNNING                 16   0.001             16         0.3        1            26.8297   1.38793        62.58 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382        10    |\n",
            "| train_cifar_86ddf_00002   PENDING                 64   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00003   PENDING                 16   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00004   PENDING                 16   0.01              16         0.3                                                    |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                    |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                    |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                    |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                    |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                    |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                    |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                    |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                    |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=14773)\u001b[0m Epoch 3\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 18 PENDING\n",
            "Current time: 2025-03-17 18:53:47. Total running time: 4min 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=1.1073757165241243 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)      loss     accuracy |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00001   RUNNING                 16   0.001             16         0.3        2             51.976   1.10738        65.79 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10            190.831   2.30382        10    |\n",
            "| train_cifar_86ddf_00002   PENDING                 64   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00003   PENDING                 16   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00004   PENDING                 16   0.01              16         0.3                                                    |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                    |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                    |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                    |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                    |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                    |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                    |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                    |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                    |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                    |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                    |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                    |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                    |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=14773)\u001b[0m Epoch 4\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 18 PENDING\n",
            "Current time: 2025-03-17 18:54:17. Total running time: 5min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.9922278304386138 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00001   RUNNING                 16   0.001             16         0.3        3            77.3684   0.992228         67.1 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382          10   |\n",
            "| train_cifar_86ddf_00002   PENDING                 64   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00003   PENDING                 16   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00004   PENDING                 16   0.01              16         0.3                                                     |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=14773)\u001b[0m Epoch 5\n",
            "\u001b[36m(train_cifar pid=14773)\u001b[0m Epoch 6\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 18 PENDING\n",
            "Current time: 2025-03-17 18:54:47. Total running time: 5min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.856197476553917 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00001   RUNNING                 16   0.001             16         0.3        5            127.319   0.856197        70.43 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10            190.831   2.30382         10    |\n",
            "| train_cifar_86ddf_00002   PENDING                 64   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00003   PENDING                 16   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00004   PENDING                 16   0.01              16         0.3                                                     |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=14773)\u001b[0m Epoch 7\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 18 PENDING\n",
            "Current time: 2025-03-17 18:55:17. Total running time: 6min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.8046007943964004 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00001   RUNNING                 16   0.001             16         0.3        6            152.251   0.804601        70.94 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10            190.831   2.30382         10    |\n",
            "| train_cifar_86ddf_00002   PENDING                 64   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00003   PENDING                 16   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00004   PENDING                 16   0.01              16         0.3                                                     |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=14773)\u001b[0m Epoch 8\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 18 PENDING\n",
            "Current time: 2025-03-17 18:55:47. Total running time: 6min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.7645727002072334 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00001   RUNNING                 16   0.001             16         0.3        7            176.654   0.764573        71.26 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10            190.831   2.30382         10    |\n",
            "| train_cifar_86ddf_00002   PENDING                 64   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00003   PENDING                 16   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00004   PENDING                 16   0.01              16         0.3                                                     |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=14773)\u001b[0m Epoch 9\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 18 PENDING\n",
            "Current time: 2025-03-17 18:56:17. Total running time: 7min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.7282831050014495 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00001   RUNNING                 16   0.001             16         0.3        8            200.804   0.728283         71.4 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10            190.831   2.30382          10   |\n",
            "| train_cifar_86ddf_00002   PENDING                 64   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00003   PENDING                 16   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00004   PENDING                 16   0.01              16         0.3                                                     |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=14773)\u001b[0m Epoch 10\n",
            "\n",
            "Trial train_cifar_86ddf_00001 completed after 10 iterations at 2025-03-17 18:56:47. Total running time: 7min 31s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00001 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         24.9316 |\n",
            "| time_total_s                             250.711 |\n",
            "| training_iteration                            10 |\n",
            "| accuracy                                   72.45 |\n",
            "| loss                                     0.65494 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial status: 2 TERMINATED | 18 PENDING\n",
            "Current time: 2025-03-17 18:56:47. Total running time: 7min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10            190.831   2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10            250.711   0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   PENDING                 64   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00003   PENDING                 16   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00004   PENDING                 16   0.01              16         0.3                                                     |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00002 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00002 config          |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                                 16 |\n",
            "| dropout                                   0.4 |\n",
            "| lr                                       0.01 |\n",
            "| num_filters                                64 |\n",
            "+-----------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=16106)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 17 PENDING\n",
            "Current time: 2025-03-17 18:57:17. Total running time: 8min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00002   RUNNING                 64   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10            190.831   2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10            250.711   0.654937        72.45 |\n",
            "| train_cifar_86ddf_00003   PENDING                 16   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00004   PENDING                 16   0.01              16         0.3                                                     |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00002 completed after 1 iterations at 2025-03-17 18:57:19. Total running time: 8min 3s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00002 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         27.4534 |\n",
            "| time_total_s                             27.4534 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                      10 |\n",
            "| loss                                      2.4345 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00003 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00003 config          |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                                 16 |\n",
            "| dropout                                   0.4 |\n",
            "| lr                                       0.01 |\n",
            "| num_filters                                16 |\n",
            "+-----------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=16334)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 16 PENDING\n",
            "Current time: 2025-03-17 18:57:47. Total running time: 8min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00003   RUNNING                 16   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00004   PENDING                 16   0.01              16         0.3                                                     |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=16334)\u001b[0m Epoch 2\n",
            "\n",
            "Trial train_cifar_86ddf_00003 completed after 2 iterations at 2025-03-17 18:58:15. Total running time: 8min 59s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00003 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         24.9555 |\n",
            "| time_total_s                             51.8705 |\n",
            "| training_iteration                             2 |\n",
            "| accuracy                                   43.16 |\n",
            "| loss                                     1.78445 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial status: 4 TERMINATED | 16 PENDING\n",
            "Current time: 2025-03-17 18:58:17. Total running time: 9min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   PENDING                 16   0.01              16         0.3                                                     |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00004 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00004 config          |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                                 16 |\n",
            "| dropout                                   0.3 |\n",
            "| lr                                       0.01 |\n",
            "| num_filters                                16 |\n",
            "+-----------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=16669)\u001b[0m Epoch 1\n",
            "\u001b[36m(train_cifar pid=16669)\u001b[0m Epoch 2\n",
            "\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 15 PENDING\n",
            "Current time: 2025-03-17 18:58:47. Total running time: 9min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00004   RUNNING                 16   0.01              16         0.3        1            27.1148   2.03414         29.26 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=16669)\u001b[0m Epoch 3\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 15 PENDING\n",
            "Current time: 2025-03-17 18:59:17. Total running time: 10min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00004   RUNNING                 16   0.01              16         0.3        2            52.2632   1.78015         43.38 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=16669)\u001b[0m Epoch 4\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 15 PENDING\n",
            "Current time: 2025-03-17 18:59:47. Total running time: 10min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00004   RUNNING                 16   0.01              16         0.3        3            77.3081   1.63702         47    |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=16669)\u001b[0m Epoch 5\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 15 PENDING\n",
            "Current time: 2025-03-17 19:00:17. Total running time: 11min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00004   RUNNING                 16   0.01              16         0.3        4           102.538    1.57105         51.52 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=16669)\u001b[0m Epoch 6\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 15 PENDING\n",
            "Current time: 2025-03-17 19:00:47. Total running time: 11min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00004   RUNNING                 16   0.01              16         0.3        5           127.755    1.52917         51.8  |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=16669)\u001b[0m Epoch 7\n",
            "\u001b[36m(train_cifar pid=16669)\u001b[0m Epoch 8\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 15 PENDING\n",
            "Current time: 2025-03-17 19:01:18. Total running time: 12min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00004   RUNNING                 16   0.01              16         0.3        7           176.512    1.46761         53.23 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=16669)\u001b[0m Epoch 9\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 15 PENDING\n",
            "Current time: 2025-03-17 19:01:48. Total running time: 12min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00004   RUNNING                 16   0.01              16         0.3        8           201.871    1.44744         55.96 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=16669)\u001b[0m Epoch 10\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 15 PENDING\n",
            "Current time: 2025-03-17 19:02:18. Total running time: 13min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00004   RUNNING                 16   0.01              16         0.3        9           226.874    1.43425         55.48 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00005   PENDING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00004 completed after 10 iterations at 2025-03-17 19:02:31. Total running time: 13min 15s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00004 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         24.9133 |\n",
            "| time_total_s                             251.787 |\n",
            "| training_iteration                            10 |\n",
            "| accuracy                                   56.25 |\n",
            "| loss                                     1.41992 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00005 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00005 config          |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                                 64 |\n",
            "| dropout                                   0.4 |\n",
            "| lr                                       0.01 |\n",
            "| num_filters                               128 |\n",
            "+-----------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=18006)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 5 TERMINATED | 1 RUNNING | 14 PENDING\n",
            "Current time: 2025-03-17 19:02:48. Total running time: 13min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00005   RUNNING                128   0.01              64         0.4                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00006   PENDING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00005 completed after 1 iterations at 2025-03-17 19:02:55. Total running time: 13min 39s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00005 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         19.3479 |\n",
            "| time_total_s                             19.3479 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                      10 |\n",
            "| loss                                     2.97851 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00006 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00006 config          |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                                 32 |\n",
            "| dropout                                   0.3 |\n",
            "| lr                                       0.01 |\n",
            "| num_filters                                32 |\n",
            "+-----------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=18196)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 6 TERMINATED | 1 RUNNING | 13 PENDING\n",
            "Current time: 2025-03-17 19:03:18. Total running time: 14min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00006   RUNNING                 32   0.01              32         0.3                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00007   PENDING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=18196)\u001b[0m Epoch 2\n",
            "\n",
            "Trial train_cifar_86ddf_00006 completed after 2 iterations at 2025-03-17 19:03:40. Total running time: 14min 24s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00006 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         20.5347 |\n",
            "| time_total_s                             41.0239 |\n",
            "| training_iteration                             2 |\n",
            "| accuracy                                   34.13 |\n",
            "| loss                                     1.82105 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00007 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00007 config          |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                                 32 |\n",
            "| dropout                                   0.4 |\n",
            "| lr                                       0.01 |\n",
            "| num_filters                                32 |\n",
            "+-----------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=18495)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 12 PENDING\n",
            "Current time: 2025-03-17 19:03:48. Total running time: 14min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00007   RUNNING                 32   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=18495)\u001b[0m Epoch 2\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 12 PENDING\n",
            "Current time: 2025-03-17 19:04:18. Total running time: 15min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00007   RUNNING                 32   0.01              32         0.4        1            22.6088   2.12308         33.79 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00008   PENDING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00007 completed after 2 iterations at 2025-03-17 19:04:25. Total running time: 15min 9s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00007 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         17.9765 |\n",
            "| time_total_s                             40.5853 |\n",
            "| training_iteration                             2 |\n",
            "| accuracy                                   44.35 |\n",
            "| loss                                      1.7895 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00008 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00008 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  32 |\n",
            "| dropout                                    0.5 |\n",
            "| lr                                       0.001 |\n",
            "| num_filters                                128 |\n",
            "+------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=18790)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 11 PENDING\n",
            "Current time: 2025-03-17 19:04:48. Total running time: 15min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00008   RUNNING                128   0.001             32         0.5                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=18790)\u001b[0m Epoch 2\n",
            "\u001b[36m(train_cifar pid=18790)\u001b[0m Epoch 3\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 11 PENDING\n",
            "Current time: 2025-03-17 19:05:18. Total running time: 16min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00008   RUNNING                128   0.001             32         0.5        2            41.7115   1.64854         52.88 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=18790)\u001b[0m Epoch 4\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 11 PENDING\n",
            "Current time: 2025-03-17 19:05:48. Total running time: 16min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00008   RUNNING                128   0.001             32         0.5        3            60.8803   1.56174         59.23 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=18790)\u001b[0m Epoch 5\n",
            "\u001b[36m(train_cifar pid=18790)\u001b[0m Epoch 6\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 11 PENDING\n",
            "Current time: 2025-03-17 19:06:18. Total running time: 17min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00008   RUNNING                128   0.001             32         0.5        5           100.489    1.46477         62.66 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=18790)\u001b[0m Epoch 7\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 11 PENDING\n",
            "Current time: 2025-03-17 19:06:48. Total running time: 17min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00008   RUNNING                128   0.001             32         0.5        6           120.752    1.41613         66.18 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=18790)\u001b[0m Epoch 8\n",
            "\u001b[36m(train_cifar pid=18790)\u001b[0m Epoch 9\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 11 PENDING\n",
            "Current time: 2025-03-17 19:07:18. Total running time: 18min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00008   RUNNING                128   0.001             32         0.5        8           160.266    1.34559         66.52 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=18790)\u001b[0m Epoch 10\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 11 PENDING\n",
            "Current time: 2025-03-17 19:07:48. Total running time: 18min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00008   RUNNING                128   0.001             32         0.5        9           179.469    1.31726         69.09 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00009   PENDING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00008 completed after 10 iterations at 2025-03-17 19:07:50. Total running time: 18min 34s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00008 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         20.2038 |\n",
            "| time_total_s                             199.673 |\n",
            "| training_iteration                            10 |\n",
            "| accuracy                                   69.72 |\n",
            "| loss                                     1.27938 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00009 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00009 config          |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                                 16 |\n",
            "| dropout                                   0.4 |\n",
            "| lr                                       0.01 |\n",
            "| num_filters                               128 |\n",
            "+-----------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=19902)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 9 TERMINATED | 1 RUNNING | 10 PENDING\n",
            "Current time: 2025-03-17 19:08:18. Total running time: 19min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00009   RUNNING                128   0.01              16         0.4                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00010   PENDING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00009 completed after 1 iterations at 2025-03-17 19:08:23. Total running time: 19min 7s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00009 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         28.7427 |\n",
            "| time_total_s                             28.7427 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                      10 |\n",
            "| loss                                      2.5325 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00010 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00010 config          |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                                 32 |\n",
            "| dropout                                   0.4 |\n",
            "| lr                                       0.01 |\n",
            "| num_filters                               128 |\n",
            "+-----------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=20133)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 10 TERMINATED | 1 RUNNING | 9 PENDING\n",
            "Current time: 2025-03-17 19:08:48. Total running time: 19min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00010   RUNNING                128   0.01              32         0.4                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00011   PENDING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00010 completed after 1 iterations at 2025-03-17 19:08:50. Total running time: 19min 33s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00010 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         22.0621 |\n",
            "| time_total_s                             22.0621 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                   18.54 |\n",
            "| loss                                     2.56122 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00011 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00011 config          |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                                 16 |\n",
            "| dropout                                   0.5 |\n",
            "| lr                                       0.01 |\n",
            "| num_filters                                64 |\n",
            "+-----------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=20338)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 11 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2025-03-17 19:09:18. Total running time: 20min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00011   RUNNING                 64   0.01              16         0.5                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00012   PENDING                 32   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00011 completed after 1 iterations at 2025-03-17 19:09:22. Total running time: 20min 5s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00011 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         26.5179 |\n",
            "| time_total_s                             26.5179 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                      10 |\n",
            "| loss                                     2.41671 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00012 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00012 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  64 |\n",
            "| dropout                                    0.3 |\n",
            "| lr                                       0.001 |\n",
            "| num_filters                                 32 |\n",
            "+------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=20560)\u001b[0m Epoch 1\n",
            "\u001b[36m(train_cifar pid=20560)\u001b[0m Epoch 2\n",
            "\n",
            "Trial status: 12 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2025-03-17 19:09:48. Total running time: 20min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00012   RUNNING                 32   0.001             64         0.3        1            16.8157   1.3805          59.35 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=20560)\u001b[0m Epoch 3\n",
            "\u001b[36m(train_cifar pid=20560)\u001b[0m Epoch 4\n",
            "Trial status: 12 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2025-03-17 19:10:18. Total running time: 21min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00012   RUNNING                 32   0.001             64         0.3        3            47.8786   0.964683        68.97 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=20560)\u001b[0m Epoch 5\n",
            "\u001b[36m(train_cifar pid=20560)\u001b[0m Epoch 6\n",
            "Trial status: 12 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2025-03-17 19:10:49. Total running time: 21min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00012   RUNNING                 32   0.001             64         0.3        5            81.0662   0.818737        71.2  |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=20560)\u001b[0m Epoch 7\n",
            "Trial status: 12 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2025-03-17 19:11:19. Total running time: 22min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00012   RUNNING                 32   0.001             64         0.3        6            97.0092   0.762917        71.71 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=20560)\u001b[0m Epoch 8\n",
            "\u001b[36m(train_cifar pid=20560)\u001b[0m Epoch 9\n",
            "Trial status: 12 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2025-03-17 19:11:49. Total running time: 22min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00001 with loss=0.6549368920922279 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00012   RUNNING                 32   0.001             64         0.3        8           128.87     0.670868        74.02 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00013   PENDING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=20560)\u001b[0m Epoch 10\n",
            "\n",
            "Trial train_cifar_86ddf_00012 completed after 10 iterations at 2025-03-17 19:12:09. Total running time: 22min 52s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00012 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         16.8002 |\n",
            "| time_total_s                             162.038 |\n",
            "| training_iteration                            10 |\n",
            "| accuracy                                    74.8 |\n",
            "| loss                                     0.58718 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00013 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00013 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  16 |\n",
            "| dropout                                    0.5 |\n",
            "| lr                                       0.001 |\n",
            "| num_filters                                128 |\n",
            "+------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=21508)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 13 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2025-03-17 19:12:19. Total running time: 23min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00013   RUNNING                128   0.001             16         0.5                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=21508)\u001b[0m Epoch 2\n",
            "Trial status: 13 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2025-03-17 19:12:49. Total running time: 23min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00013   RUNNING                128   0.001             16         0.5        1            29.2571   2.0089          38.78 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00014   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00013 completed after 2 iterations at 2025-03-17 19:13:10. Total running time: 23min 53s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00013 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                           27.31 |\n",
            "| time_total_s                             56.5671 |\n",
            "| training_iteration                             2 |\n",
            "| accuracy                                   43.73 |\n",
            "| loss                                     1.84157 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00014 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00014 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  32 |\n",
            "| dropout                                    0.3 |\n",
            "| lr                                       0.001 |\n",
            "| num_filters                                128 |\n",
            "+------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=21881)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 14 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2025-03-17 19:13:19. Total running time: 24min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00014   RUNNING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=21881)\u001b[0m Epoch 2\n",
            "Trial status: 14 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2025-03-17 19:13:49. Total running time: 24min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00014   RUNNING                128   0.001             32         0.3        1            21.6726   1.71297         54.62 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=21881)\u001b[0m Epoch 3\n",
            "Trial status: 14 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2025-03-17 19:14:19. Total running time: 25min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00014   RUNNING                128   0.001             32         0.3        2            42.9743   1.36513         62.34 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=21881)\u001b[0m Epoch 4\n",
            "\u001b[36m(train_cifar pid=21881)\u001b[0m Epoch 5\n",
            "Trial status: 14 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2025-03-17 19:14:49. Total running time: 25min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00014   RUNNING                128   0.001             32         0.3        4            84.5224   1.18312         67.9  |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=21881)\u001b[0m Epoch 6\n",
            "Trial status: 14 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2025-03-17 19:15:19. Total running time: 26min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00014   RUNNING                128   0.001             32         0.3        5           105.4      1.10631         67.39 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=21881)\u001b[0m Epoch 7\n",
            "\u001b[36m(train_cifar pid=21881)\u001b[0m Epoch 8\n",
            "Trial status: 14 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2025-03-17 19:15:49. Total running time: 26min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00014   RUNNING                128   0.001             32         0.3        7           147.767    0.986925        71.59 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=21881)\u001b[0m Epoch 9\n",
            "Trial status: 14 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2025-03-17 19:16:19. Total running time: 27min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00014   RUNNING                128   0.001             32         0.3        8           168.3      0.938668        71.36 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=21881)\u001b[0m Epoch 10\n",
            "\n",
            "Trial train_cifar_86ddf_00014 completed after 10 iterations at 2025-03-17 19:16:45. Total running time: 27min 29s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00014 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         20.3944 |\n",
            "| time_total_s                             209.447 |\n",
            "| training_iteration                            10 |\n",
            "| accuracy                                   73.56 |\n",
            "| loss                                     0.84381 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial status: 15 TERMINATED | 5 PENDING\n",
            "Current time: 2025-03-17 19:16:49. Total running time: 27min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   PENDING                 16   0.001             64         0.5                                                     |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00015 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00015 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  64 |\n",
            "| dropout                                    0.5 |\n",
            "| lr                                       0.001 |\n",
            "| num_filters                                 16 |\n",
            "+------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=23041)\u001b[0m Epoch 1\n",
            "\u001b[36m(train_cifar pid=23041)\u001b[0m Epoch 2\n",
            "\n",
            "Trial status: 15 TERMINATED | 1 RUNNING | 4 PENDING\n",
            "Current time: 2025-03-17 19:17:19. Total running time: 28min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00015   RUNNING                 16   0.001             64         0.5        1            17.9963   1.48645         57.23 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=23041)\u001b[0m Epoch 3\n",
            "\u001b[36m(train_cifar pid=23041)\u001b[0m Epoch 4\n",
            "Trial status: 15 TERMINATED | 1 RUNNING | 4 PENDING\n",
            "Current time: 2025-03-17 19:17:49. Total running time: 28min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00015   RUNNING                 16   0.001             64         0.5        3            48.1641   1.10022         66.03 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=23041)\u001b[0m Epoch 5\n",
            "\u001b[36m(train_cifar pid=23041)\u001b[0m Epoch 6\n",
            "Trial status: 15 TERMINATED | 1 RUNNING | 4 PENDING\n",
            "Current time: 2025-03-17 19:18:19. Total running time: 29min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00015   RUNNING                 16   0.001             64         0.5        5            78.1707   0.983354        68.62 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=23041)\u001b[0m Epoch 7\n",
            "\u001b[36m(train_cifar pid=23041)\u001b[0m Epoch 8\n",
            "Trial status: 15 TERMINATED | 1 RUNNING | 4 PENDING\n",
            "Current time: 2025-03-17 19:18:49. Total running time: 29min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00015   RUNNING                 16   0.001             64         0.5        7           108.833    0.898186        69.52 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=23041)\u001b[0m Epoch 9\n",
            "\u001b[36m(train_cifar pid=23041)\u001b[0m Epoch 10\n",
            "Trial status: 15 TERMINATED | 1 RUNNING | 4 PENDING\n",
            "Current time: 2025-03-17 19:19:19. Total running time: 30min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00015   RUNNING                 16   0.001             64         0.5        9           141.114    0.842528        71.51 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00016   PENDING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00015 completed after 10 iterations at 2025-03-17 19:19:26. Total running time: 30min 10s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00015 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         15.0049 |\n",
            "| time_total_s                             156.119 |\n",
            "| training_iteration                            10 |\n",
            "| accuracy                                   72.29 |\n",
            "| loss                                     0.82195 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00016 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00016 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  32 |\n",
            "| dropout                                    0.3 |\n",
            "| lr                                       0.001 |\n",
            "| num_filters                                128 |\n",
            "+------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=23960)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 16 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2025-03-17 19:19:50. Total running time: 30min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00016   RUNNING                128   0.001             32         0.3                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=23960)\u001b[0m Epoch 2\n",
            "\u001b[36m(train_cifar pid=23960)\u001b[0m Epoch 3\n",
            "Trial status: 16 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2025-03-17 19:20:20. Total running time: 31min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00016   RUNNING                128   0.001             32         0.3        2            41.9476   1.28823         64.72 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=23960)\u001b[0m Epoch 4\n",
            "Trial status: 16 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2025-03-17 19:20:50. Total running time: 31min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00016   RUNNING                128   0.001             32         0.3        3            62.5042   1.16513         66.9  |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=23960)\u001b[0m Epoch 5\n",
            "\u001b[36m(train_cifar pid=23960)\u001b[0m Epoch 6\n",
            "Trial status: 16 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2025-03-17 19:21:20. Total running time: 32min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00016   RUNNING                128   0.001             32         0.3        5           102.519    1.00145         70.8  |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=23960)\u001b[0m Epoch 7\n",
            "Trial status: 16 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2025-03-17 19:21:50. Total running time: 32min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00016   RUNNING                128   0.001             32         0.3        6           121.758    0.927654        73.53 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=23960)\u001b[0m Epoch 8\n",
            "\u001b[36m(train_cifar pid=23960)\u001b[0m Epoch 9\n",
            "Trial status: 16 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2025-03-17 19:22:20. Total running time: 33min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00016   RUNNING                128   0.001             32         0.3        8           162.392    0.811358        74.82 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=23960)\u001b[0m Epoch 10\n",
            "Trial status: 16 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2025-03-17 19:22:50. Total running time: 33min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00016   RUNNING                128   0.001             32         0.3        9           183.284    0.756297        73.97 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00017   PENDING                 16   0.01              64         0.3                                                     |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00016 completed after 10 iterations at 2025-03-17 19:22:53. Total running time: 33min 36s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00016 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                          19.603 |\n",
            "| time_total_s                             202.887 |\n",
            "| training_iteration                            10 |\n",
            "| accuracy                                   76.11 |\n",
            "| loss                                     0.69824 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00017 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00017 config          |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                                 64 |\n",
            "| dropout                                   0.3 |\n",
            "| lr                                       0.01 |\n",
            "| num_filters                                16 |\n",
            "+-----------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=25078)\u001b[0m Epoch 1\n",
            "\u001b[36m(train_cifar pid=25078)\u001b[0m Epoch 2\n",
            "\n",
            "Trial status: 17 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2025-03-17 19:23:20. Total running time: 34min 4s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00017   RUNNING                 16   0.01              64         0.3        1            17.8107   1.96777         39.9  |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00016   TERMINATED             128   0.001             32         0.3       10           202.887    0.698243        76.11 |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=25078)\u001b[0m Epoch 3\n",
            "\u001b[36m(train_cifar pid=25078)\u001b[0m Epoch 4\n",
            "Trial status: 17 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2025-03-17 19:23:50. Total running time: 34min 34s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00017   RUNNING                 16   0.01              64         0.3        3            48.3795   1.54459         51.91 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00016   TERMINATED             128   0.001             32         0.3       10           202.887    0.698243        76.11 |\n",
            "| train_cifar_86ddf_00018   PENDING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00017 completed after 4 iterations at 2025-03-17 19:24:01. Total running time: 34min 44s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00017 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         15.3009 |\n",
            "| time_total_s                             63.6804 |\n",
            "| training_iteration                             4 |\n",
            "| accuracy                                   56.55 |\n",
            "| loss                                     1.46376 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00018 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00018 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  64 |\n",
            "| dropout                                    0.3 |\n",
            "| lr                                       0.001 |\n",
            "| num_filters                                 16 |\n",
            "+------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=25501)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 18 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2025-03-17 19:24:20. Total running time: 35min 4s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00018   RUNNING                 16   0.001             64         0.3                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00016   TERMINATED             128   0.001             32         0.3       10           202.887    0.698243        76.11 |\n",
            "| train_cifar_86ddf_00017   TERMINATED              16   0.01              64         0.3        4            63.6804   1.46376         56.55 |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=25501)\u001b[0m Epoch 2\n",
            "\u001b[36m(train_cifar pid=25501)\u001b[0m Epoch 3\n",
            "Trial status: 18 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2025-03-17 19:24:50. Total running time: 35min 34s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00018   RUNNING                 16   0.001             64         0.3        2            33.1976   1.05615         65.88 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00016   TERMINATED             128   0.001             32         0.3       10           202.887    0.698243        76.11 |\n",
            "| train_cifar_86ddf_00017   TERMINATED              16   0.01              64         0.3        4            63.6804   1.46376         56.55 |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=25501)\u001b[0m Epoch 4\n",
            "\u001b[36m(train_cifar pid=25501)\u001b[0m Epoch 5\n",
            "Trial status: 18 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2025-03-17 19:25:20. Total running time: 36min 4s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00018   RUNNING                 16   0.001             64         0.3        4            63.9882   0.85901         70.63 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00016   TERMINATED             128   0.001             32         0.3       10           202.887    0.698243        76.11 |\n",
            "| train_cifar_86ddf_00017   TERMINATED              16   0.01              64         0.3        4            63.6804   1.46376         56.55 |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=25501)\u001b[0m Epoch 6\n",
            "\u001b[36m(train_cifar pid=25501)\u001b[0m Epoch 7\n",
            "Trial status: 18 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2025-03-17 19:25:50. Total running time: 36min 34s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00018   RUNNING                 16   0.001             64         0.3        6            95.0203   0.742581        72.3  |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00016   TERMINATED             128   0.001             32         0.3       10           202.887    0.698243        76.11 |\n",
            "| train_cifar_86ddf_00017   TERMINATED              16   0.01              64         0.3        4            63.6804   1.46376         56.55 |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=25501)\u001b[0m Epoch 8\n",
            "\u001b[36m(train_cifar pid=25501)\u001b[0m Epoch 9\n",
            "Trial status: 18 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2025-03-17 19:26:20. Total running time: 37min 4s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00012 with loss=0.5871817920823841 and params={'num_filters': 32, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00018   RUNNING                 16   0.001             64         0.3        8           126.375    0.654808        72.39 |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00016   TERMINATED             128   0.001             32         0.3       10           202.887    0.698243        76.11 |\n",
            "| train_cifar_86ddf_00017   TERMINATED              16   0.01              64         0.3        4            63.6804   1.46376         56.55 |\n",
            "| train_cifar_86ddf_00019   PENDING                 64   0.01              32         0.5                                                     |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=25501)\u001b[0m Epoch 10\n",
            "\n",
            "Trial train_cifar_86ddf_00018 completed after 10 iterations at 2025-03-17 19:26:42. Total running time: 37min 26s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00018 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         15.3034 |\n",
            "| time_total_s                             156.985 |\n",
            "| training_iteration                            10 |\n",
            "| accuracy                                   72.54 |\n",
            "| loss                                     0.58091 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_86ddf_00019 started with configuration:\n",
            "+-----------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00019 config          |\n",
            "+-----------------------------------------------+\n",
            "| batch_size                                 32 |\n",
            "| dropout                                   0.5 |\n",
            "| lr                                       0.01 |\n",
            "| num_filters                                64 |\n",
            "+-----------------------------------------------+\n",
            "\u001b[36m(train_cifar pid=26426)\u001b[0m Epoch 1\n",
            "\n",
            "Trial status: 19 TERMINATED | 1 RUNNING\n",
            "Current time: 2025-03-17 19:26:50. Total running time: 37min 34s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00018 with loss=0.5809078816791324 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00019   RUNNING                 64   0.01              32         0.5                                                     |\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00016   TERMINATED             128   0.001             32         0.3       10           202.887    0.698243        76.11 |\n",
            "| train_cifar_86ddf_00017   TERMINATED              16   0.01              64         0.3        4            63.6804   1.46376         56.55 |\n",
            "| train_cifar_86ddf_00018   TERMINATED              16   0.001             64         0.3       10           156.985    0.580908        72.54 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-03-17 19:27:08,836\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_cifar_2025-03-17_18-49-16' in 0.0223s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_cifar_86ddf_00019 completed after 1 iterations at 2025-03-17 19:27:08. Total running time: 37min 52s\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_86ddf_00019 result             |\n",
            "+--------------------------------------------------+\n",
            "| checkpoint_dir_name                              |\n",
            "| time_this_iter_s                         21.4927 |\n",
            "| time_total_s                             21.4927 |\n",
            "| training_iteration                             1 |\n",
            "| accuracy                                   26.52 |\n",
            "| loss                                     2.37832 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial status: 20 TERMINATED\n",
            "Current time: 2025-03-17 19:27:08. Total running time: 37min 52s\n",
            "Logical resource usage: 2.0/2 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "Current best trial: 86ddf_00018 with loss=0.5809078816791324 and params={'num_filters': 16, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                status         num_filters      lr     batch_size     dropout     iter     total time (s)       loss     accuracy |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_86ddf_00000   TERMINATED              64   0.01              32         0.4       10           190.831    2.30382         10    |\n",
            "| train_cifar_86ddf_00001   TERMINATED              16   0.001             16         0.3       10           250.711    0.654937        72.45 |\n",
            "| train_cifar_86ddf_00002   TERMINATED              64   0.01              16         0.4        1            27.4534   2.4345          10    |\n",
            "| train_cifar_86ddf_00003   TERMINATED              16   0.01              16         0.4        2            51.8705   1.78445         43.16 |\n",
            "| train_cifar_86ddf_00004   TERMINATED              16   0.01              16         0.3       10           251.787    1.41992         56.25 |\n",
            "| train_cifar_86ddf_00005   TERMINATED             128   0.01              64         0.4        1            19.3479   2.97851         10    |\n",
            "| train_cifar_86ddf_00006   TERMINATED              32   0.01              32         0.3        2            41.0239   1.82105         34.13 |\n",
            "| train_cifar_86ddf_00007   TERMINATED              32   0.01              32         0.4        2            40.5852   1.7895          44.35 |\n",
            "| train_cifar_86ddf_00008   TERMINATED             128   0.001             32         0.5       10           199.673    1.27938         69.72 |\n",
            "| train_cifar_86ddf_00009   TERMINATED             128   0.01              16         0.4        1            28.7427   2.5325          10    |\n",
            "| train_cifar_86ddf_00010   TERMINATED             128   0.01              32         0.4        1            22.0621   2.56122         18.54 |\n",
            "| train_cifar_86ddf_00011   TERMINATED              64   0.01              16         0.5        1            26.5179   2.41671         10    |\n",
            "| train_cifar_86ddf_00012   TERMINATED              32   0.001             64         0.3       10           162.038    0.587182        74.8  |\n",
            "| train_cifar_86ddf_00013   TERMINATED             128   0.001             16         0.5        2            56.5671   1.84157         43.73 |\n",
            "| train_cifar_86ddf_00014   TERMINATED             128   0.001             32         0.3       10           209.447    0.843809        73.56 |\n",
            "| train_cifar_86ddf_00015   TERMINATED              16   0.001             64         0.5       10           156.119    0.821954        72.29 |\n",
            "| train_cifar_86ddf_00016   TERMINATED             128   0.001             32         0.3       10           202.887    0.698243        76.11 |\n",
            "| train_cifar_86ddf_00017   TERMINATED              16   0.01              64         0.3        4            63.6804   1.46376         56.55 |\n",
            "| train_cifar_86ddf_00018   TERMINATED              16   0.001             64         0.3       10           156.985    0.580908        72.54 |\n",
            "| train_cifar_86ddf_00019   TERMINATED              64   0.01              32         0.5        1            21.4927   2.37832         26.52 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Best Config: {'num_filters': 16, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.3}\n",
            "Best Validation Accuracy: 72.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = results.get_dataframe()"
      ],
      "metadata": {
        "id": "J_nC-Cjub3XM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df[\"config/lr\"], df[\"accuracy\"], c=\"blue\", alpha=0.7)\n",
        "plt.xscale(\"log\")  # Log scale for better visualization\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.title(\"Tuning Results: Accuracy vs. Learning Rate\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "5nzpRZCFk-i9",
        "outputId": "6368512f-f330-4da0-e0bf-e426ea7cec3f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df[\"config/num_filters\"], df[\"accuracy\"], c=\"blue\", alpha=0.7)\n",
        "plt.xscale(\"log\")  # Log scale for better visualization\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.title(\"Tuning Results: Accuracy vs. Learning Rate\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "BVsgDMCulI7j",
        "outputId": "73cd3624-e5fb-4960-e173-9977cdd8995a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df[\"config/batch_size\"], df[\"accuracy\"], c=\"blue\", alpha=0.7)\n",
        "plt.xscale(\"log\")  # Log scale for better visualization\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.title(\"Tuning Results: Accuracy vs. Learning Rate\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "95FhAu5tlZsy",
        "outputId": "a28466f5-5e7b-439a-940a-40305b4c17e5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df[\"config/dropout\"], df[\"accuracy\"], c=\"blue\", alpha=0.7)\n",
        "plt.xscale(\"log\")  # Log scale for better visualization\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.title(\"Tuning Results: Accuracy vs. Learning Rate\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "m9cSyX0AlcM5",
        "outputId": "08e572bb-ed3d-42ca-ec0a-60ca92bc1660"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}